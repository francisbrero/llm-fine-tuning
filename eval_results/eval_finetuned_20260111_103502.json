{
  "model_type": "finetuned",
  "timestamp": "2026-01-11T10:02:09.404122",
  "num_examples": 30,
  "overall": {
    "json_valid": 30,
    "field_accuracy": 0.4088888888888889,
    "total_latency_ms": 1971556.2345981598,
    "json_valid_rate": 1.0,
    "avg_latency_ms": 65718.54115327199
  },
  "by_category": {
    "standard": {
      "json_valid": 9,
      "field_accuracy": 0.3888888888888889,
      "count": 9,
      "json_valid_rate": 1.0
    },
    "slang": {
      "json_valid": 15,
      "field_accuracy": 0.5622222222222223,
      "count": 15,
      "json_valid_rate": 1.0
    },
    "ambiguous": {
      "json_valid": 1,
      "field_accuracy": 0.3333333333333333,
      "count": 1,
      "json_valid_rate": 1.0
    },
    "adversarial": {
      "json_valid": 5,
      "field_accuracy": 0.0,
      "count": 5,
      "json_valid_rate": 1.0
    }
  },
  "by_difficulty": {
    "medium": {
      "json_valid": 13,
      "field_accuracy": 0.423076923076923,
      "count": 13,
      "json_valid_rate": 1.0
    },
    "hard": {
      "json_valid": 17,
      "field_accuracy": 0.3980392156862745,
      "count": 17,
      "json_valid_rate": 1.0
    }
  },
  "by_field": {
    "intent_type": {
      "correct": 7,
      "total": 26
    },
    "motion": {
      "correct": 7,
      "total": 25
    },
    "role_assumption": {
      "correct": 15,
      "total": 25
    },
    "account_scope": {
      "correct": 16,
      "total": 25
    },
    "time_horizon": {
      "correct": 17,
      "total": 25
    },
    "geography_scope": {
      "correct": 0,
      "total": 1
    },
    "output_format": {
      "correct": 1,
      "total": 3
    },
    "clarification_needed": {
      "correct": 1,
      "total": 7
    }
  },
  "examples": [
    {
      "prompt": "Help me prepare for my QBR",
      "category": "standard",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.6,
      "latency_ms": 73476.13906860352
    },
    {
      "prompt": "Which accounts haven't been touched in 30 days?",
      "category": "standard",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.4,
      "latency_ms": 44487.541913986206
    },
    {
      "prompt": "Net new ARR this quarter",
      "category": "standard",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.2,
      "latency_ms": 54448.25291633606
    },
    {
      "prompt": "Show me SQLs from the webinar",
      "category": "standard",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.0,
      "latency_ms": 123439.41617012024
    },
    {
      "prompt": "Who's ghosting us?",
      "category": "slang",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.6666666666666666,
      "latency_ms": 45858.14309120178
    },
    {
      "prompt": "Warm intros I can ask for",
      "category": "slang",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.6,
      "latency_ms": 44639.386892318726
    },
    {
      "prompt": "Logos we can flip from Competitor Y",
      "category": "slang",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.6,
      "latency_ms": 43994.45033073425
    },
    {
      "prompt": "Multi-thread opportunities in enterprise",
      "category": "slang",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.6,
      "latency_ms": 62818.33600997925
    },
    {
      "prompt": "Stuck deals I need to unstick",
      "category": "slang",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.8,
      "latency_ms": 73379.80008125305
    },
    {
      "prompt": "Champion changes at key accounts",
      "category": "slang",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.4,
      "latency_ms": 43161.14401817322
    },
    {
      "prompt": "Pipeline coverage for next quarter",
      "category": "standard",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.6,
      "latency_ms": 39293.29800605774
    },
    {
      "prompt": "Accounts with product usage drop",
      "category": "standard",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.2,
      "latency_ms": 56394.031047821045
    },
    {
      "prompt": "Where should I spend my time today?",
      "category": "ambiguous",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.3333333333333333,
      "latency_ms": 85612.30206489563
    },
    {
      "prompt": "stuff",
      "category": "adversarial",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.0,
      "latency_ms": 78940.15073776245
    },
    {
      "prompt": "Tell me about the weather",
      "category": "adversarial",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.0,
      "latency_ms": 46913.34390640259
    },
    {
      "prompt": "Generate a poem about sales",
      "category": "adversarial",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.0,
      "latency_ms": 41276.03483200073
    },
    {
      "prompt": "blahblahblah",
      "category": "adversarial",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.0,
      "latency_ms": 74504.98366355896
    },
    {
      "prompt": "Book me a flight to NYC",
      "category": "adversarial",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.0,
      "latency_ms": 43639.64581489563
    },
    {
      "prompt": "PLG accounts ready for sales touch",
      "category": "slang",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.6,
      "latency_ms": 45973.82879257202
    },
    {
      "prompt": "Closed-lost we can re-engage",
      "category": "slang",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.8,
      "latency_ms": 210324.471950531
    },
    {
      "prompt": "Give me the TL;DR on my pipeline",
      "category": "slang",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.6666666666666666,
      "latency_ms": 55437.536001205444
    },
    {
      "prompt": "LATAM expansion targets",
      "category": "standard",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.5,
      "latency_ms": 51836.19499206543
    },
    {
      "prompt": "Trials converting this week",
      "category": "standard",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.4,
      "latency_ms": 73772.91679382324
    },
    {
      "prompt": "High NPS accounts for case studies",
      "category": "standard",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.6,
      "latency_ms": 82438.34781646729
    },
    {
      "prompt": "Slipping deals I need to save",
      "category": "slang",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.4,
      "latency_ms": 37167.287826538086
    },
    {
      "prompt": "Low-hanging fruit in my territory",
      "category": "slang",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.6,
      "latency_ms": 69060.09578704834
    },
    {
      "prompt": "What's the ask for the all-hands?",
      "category": "slang",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.16666666666666666,
      "latency_ms": 45693.18985939026
    },
    {
      "prompt": "Spiff-eligible deals this month",
      "category": "slang",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.8,
      "latency_ms": 69536.59009933472
    },
    {
      "prompt": "Build me a hit list for next week",
      "category": "slang",
      "difficulty": "medium",
      "is_valid": true,
      "field_accuracy": 0.3333333333333333,
      "latency_ms": 76420.68099975586
    },
    {
      "prompt": "Which whales are in play?",
      "category": "slang",
      "difficulty": "hard",
      "is_valid": true,
      "field_accuracy": 0.4,
      "latency_ms": 77618.69311332703
    }
  ]
}